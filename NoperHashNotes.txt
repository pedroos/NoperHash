NoperHash genericization topics to cover in new article [60d]
- The mean is an "aid"; ideally substituted for another number over 
  the list, but actually, semantically, it makes 
    sense that a mean would be a "kind of representation" of a list; 
    so it's semantic
    - But, operationally, Generic Math doesn't admit operations between 
      different number types; so a rolling average 
      must be implemented
      - But division for integral types may be "lossy", or not 
        fractional; so the useful use case of computing the rolling 
        average of a list of bytes (for strings) would compute an 
        useless mean; possibly with many collisions
        - Study this byte list mean and quantify collisions
      - Study differences in values between a mean and a rolling mean
    - Even with a properly implemented rolling mean, the division is 
      integral (not fractional) for integral number types; this means 
      it's much more subject to collisions and probably compromises 
      the algorithm
      - The ideia of the algorithm is that any number that is a real 
        number *is* first converted to a real number and then used as 
        an input to the algorithm
        - This conversion between number systems, however, is not 
          supported transparently by Generic Math
        - Said another way, it's not possible to operate numbers on 
          different number systems, even if the operations are 
          equivalent
        - This means the algorithm would, in the end, just be over 
          floating point (or real numbers), and not be generic anymore 
          at all
        - Since Generic Math supports a "is real number" check, we can 
          simply throw if the input is not real (but keep the 
          algorithm generic)
  - "Normalization" (magnitude adjustment) uses "Floor", which in 
    Generic Math is referred to as being a floating-point-exclusive 
    operation (not a real number operation); but isn't it just the 
    Infimum?
    - If it's the Infimum, the algorithm is still Mathematical
    - Wolfram documentation says its `Floor` function is the largest 
      integer lower than a number; so an Infimum
    - Study differences between floating point concepts derived from 
      real number concepts and the actual real number concepts
      - Assembly language names some float data types as "reals"
    - Update: apparently, this is now part of normal number theory in 
      maths (look up Significant Figures, multiplication and division 
      precision)

NoperHash, what do we need to do?
- Check correctness across different processors and operating systems
- Compare mathematical complexity against competitors
- Publish collision measurements
- Differentiate between collisions due to floating point error, or 
  due to mathematical properties (analyze and explain collisions)
  - Given a mathematical collision, generate the collision set and 
    calculate its histogram
- Document the library
- Use abstract mathematics to find the points of doubt about the 
  algorithm being mathematical vs. using "computer concepts" (from 
  what I remember, it was about using "ceiling" or "floor" in `log`, 
  or something like that). If possible, formulate a purely 
  mathematical version

NoperHash high-level view
- Make it completely mathematically determined (if it's not already 
  so), such that performance is its "major flaw"
- Then, discover exactly why it performs badly: zoom in up to hardware 
  and to the exponential algorithm in use
- Then, either build an alternative, performant calculation (maybe 
  branching into a new version of the algorithm), if it's limited 
  mathematically, or find an architecture or software implementation 
  which implements fast exponentiation
  
- Doubles to ints
  - Can't a double be converted to an int (or some other integer) by 
    a suitable multiplication (we may have already done this in 
    LINQPad)? Then, we can store (and compare) NoperHashes as ints, 
    which is fully precise! Precision or collision tests can be 
    performed a priori for a given epsilon and representative universe 
    of inputs and the epsilon can be configured into the algorithm 
    which then returns integers on that precision, which, according to 
    the tests, should be collision-free.
    
- Mmm
  - Are exponentiations between 1 and 9 only (digit-by-digit after 
    magnitude reduction)? If so, then the results can be hard-coded 
    and no calculation is performed? 9 ^ 9 is 387420489, which fits an 
    `int`.
    
- An application: symbols
  - Instead of maintaining symbol string lists or imprecise hashes to 
    enforce uniqueness of symbols, maintain instead NoperHashes